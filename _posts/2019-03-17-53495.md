---
layout: post
title: 取得した文字列の操作及び出力python
date: 2019-03-17 08:50:46
categories: python python3 web-scraping beautifulsoup
---
<p>食べログのサイトから営業時間を取得し、平日/土日祝をそれぞれ開始日時と終了日時に分けてcsvに出力できればと考えています。<br>
今の問題は</p>

<ol>
<li>取得済みの平日/土日祝で別々のリストに入った文字列からxx:xxという時刻の文字列を取り出し出力すること。今のままだと1800みたくなってしまいます。findallで取得したものの中に":"や"～"という文字は除外されてしまうみたいです。</li>
<li>”～”の文字列に反応して開始時刻と終了時刻を別々に区切って出力すること。 18:00~23:00<br>
なら　18:00と23:00を別々のセルに</li>
<li>全角の文字列にも対処できるようにしたい</li>
</ol>

<p>以上です宜しくお願いします。</p>

<pre><code>import csv
import re
import requests
from bs4 import BeautifulSoup


def get_dotwlefts(tablink):
    response = requests.get(tablink)
    html = response.content
    soup = BeautifulSoup(html, "html.parser")
    dotwfound = soup.select_one(
        "#contents-rstdata &gt; div.rstinfo-table &gt; table:nth-child(2) &gt; tbody &gt; tr:nth-child(7) &gt; td &gt; p"
    )
    if dotwfound is not None:
        dotw = dotwfound.text
    if dotwfound is None:
        dotw = ""
    m = re.search(r"\[土|【土|\[土・日【日|土・日|日祝|土日祝|日・祝|\[日・祝|土・日・祝|土日|土、日|\[日", dotw, flags=re.DOTALL)
    y = m.start() if m else None
    dotwlefts = left(dotw, y)
    dotwrights = right(dotw, y)
    if dotwlefts == dotwrights:
        dotwrights = ""
    return dotwlefts


def get_dotwrights(tablink):
    response = requests.get(tablink)
    html = response.content
    soup = BeautifulSoup(html, "html.parser")
    dotwfound = soup.select_one(
        "#contents-rstdata &gt; div.rstinfo-table &gt; table:nth-child(2) &gt; tbody &gt; tr:nth-child(7) &gt; td &gt; p"
    )
    if dotwfound is not None:
        dotw = dotwfound.text
    if dotwfound is None:
        dotw = ""
    m = re.search(r"\[土|【土|\[土・日【日|土・日|日祝|土日祝|日・祝|\[日・祝|土・日・祝|土日|土、日|\[金|【金|\[日|金/土", dotw, flags=re.DOTALL)
    y = m.start() if m else None
    dotwlefts = left(dotw, y)
    dotwrights = right(dotw, y)
    if dotwlefts == dotwrights:
        dotwrights = ""
    return dotwrights


def left(text, n):
    return text[:n]


def right(text, n):
    return text[n:]


def get_eachpage(url):
    response = requests.get(url)
    html = response.content
    soup = BeautifulSoup(html, "html.parser")
    tablinks = [
        "https://icotto.jp" + each.get("href")
        for each in soup.find_all("a", {"class": "p-presses-show-spot__source--image"})
    ]
    for tablink in tablinks:
        dotwleft = get_dotwlefts(tablink)
        dotwright = get_dotwrights(tablink)
        dotwleft = re.findall(r"[0-9０－９~〜:：]+", dotwleft)
        #dotwleft = "".join(re.findall("[0-9]{1}|[0-9]{2}:[0-9]{2}～[0-9]{1}|[0-9]{2}:[0-9]{2}", dotwleft))
        #dotwright = "".join(re.findall("[0-9]{1}|[0-9]{2}:[0-9]{2}~[0-9]{1}|[0-9]{2}:[0-9]{2}", dotwright))
        print(dotwleft)
        print(dotwright)


url = "https://icotto.jp/presses/15108"
get_eachpage(url)
</code></pre>
