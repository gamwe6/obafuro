---
layout: post
title: 音声認識の結果が出てから次の処理に進みたい（DispatchSemaphoreを使っています
date: 2018-08-10 08:30:31
categories: swift ios swift4
---
```
    let request = SFSpeechURLRecognitionRequest(url:voiceFileURL)
    let semaphore = DispatchSemaphore(value: 0)
    let queue = DispatchQueue.global(qos: .default)
    queue.async {
        self.speechRecognizer.recognitionTask(with: request){ (result, error) in
        guard let result = result else {
            print("=============Recognition failed, so check error for details and handle it")
            return
        }
        if result.isFinal {
            self.recognitionText = (result.bestTranscription.formattedString)
            semaphore.signal()
            print("============A recognitionText : ",self.recognitionText)
        }
    }
    }
    semaphore.wait()
    print("============wait done ")
```

<p>recognitionTaskの終了をisFinalで調べてsemaphore.signal()を行いsemaphore.wait()を抜けたいのですが、semaphore.wait()で止まってしまいます。　なにか基本的に間違いを起こしているでしょうか？</p>

<hr>

```
@IBAction func addButton(_ sender: UIBarButtonItem) {

    let todo = Todo(context: self.context)
    let voiceFile = audioInit()

    todo.voiceFileName = voiceFile
    todo.dateTime = Date()
    audioRecorder?.record(forDuration:10.0)
    print("=================:Sleep Start11")
    Thread.sleep(forTimeInterval: 11.0)
     print("=================:Sleep End11")
    todo.text = voiceRecognition(voiceFileName:voiceFile)

    self.todos.append(todo)
    (UIApplication.shared.delegate as! AppDelegate).saveContext()
}


   func voiceRecognition(voiceFileName : String) -&gt; String{

    let fileMgr = FileManager.default
    let dirPaths = fileMgr.urls(for: .documentDirectory,in: .userDomainMask)
    let voiceFileURL = dirPaths[0].appendingPathComponent(voiceFileName)

    let request = SFSpeechURLRecognitionRequest(url:voiceFileURL)
    let semaphore = DispatchSemaphore(value: 0)
    let queue = DispatchQueue.global(qos: .default)
    queue.async {
        self.speechRecognizer.recognitionTask(with: request){ (result, error) in
        guard let result = result else {
            print("=============Recognition failed, so check error for details and handle it")
            return
        }
        if result.isFinal {
            self.recognitionText = (result.bestTranscription.formattedString)
            semaphore.signal()
            print("============A recognitionText : ",self.recognitionText)
        }
    }
    }
    semaphore.wait()
    print("============wait done ")
    return(self.recognitionText)
}
```

<p>ソースコードを関連箇所に変更しました。ご指摘通り@IBActionのなかでwaitしています。やりたいことは、addButtonが押されると音声を録音し、音声認識して結果をCoreDataに保存することです。</p>

<p>CoreDataの定義は以下です。<br>
CoreData Entitis : Todo<br>
Attribute       Type<br>
・dateTime       Date<br>
・text           String<br>
・voiceFileName  String</p>
