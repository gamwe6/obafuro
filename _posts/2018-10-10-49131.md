---
layout: post
title: "kinectで青玉の認識をopencvを使って行いたいです"
date: 2018-10-10 07:35:21
categories: opencv kinect
---
<p>エラーメッセージ</p>

<pre><code>mainの戻り値の型にはintを使用してくださいvoidは使用できません。
int main(void) オーバーロード関数はint main(void)と戻り値の型のみが異なります
</code></pre>

<p>この２つがどうしても消えません<br>
よろしくお願いいたします</p>

<p>引用元：<a href="http://kivantium.hateblo.jp/entry/20120822/p1" rel="nofollow noreferrer">http://kivantium.hateblo.jp/entry/20120822/p1</a><br>
　　　　Kinect 実践プログラム　杉浦司</p>

<pre class="lang-c prettyprint-override"><code>#include"stdafx.h"
#include &lt;time.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;iostream&gt;
#include &lt;sstream&gt;
#include "opencv/Labeling.h"
#include &lt;cstdio&gt;

void main()
{
    try {
        KinectSample kinect;
        kinect.initialize();
        kinect.run();
        using namespace cv;
        using namespace std;
        int num;
        int main(); {
            try {
                VideoCapture capture(0);
                Mat RGBMap, Cloud, valid;
                IplImage ipl_RGB;
                IplImage *imgR, *imgG = 0, *imgB;
                IplImage *imgThreshold_R, *imgThreshold_G, *imgThreshold_B, *imgResult, *imgTmp, *RGB_image;
                int x, y;
                short *dst;
                LabelingBS labeling;
                RegionInfoBS    *ri;
                dst = new short[640 * 480];

                imgThreshold_R = cvCreateImage(cvSize(640, 480), IPL_DEPTH_8U, 1);
                imgThreshold_G = cvCreateImage(cvSize(640, 480), IPL_DEPTH_8U, 1);
                imgThreshold_B = cvCreateImage(cvSize(640, 480), IPL_DEPTH_8U, 1);
                imgResult = cvCreateImage(cvSize(640, 480), IPL_DEPTH_8U, 1);
                imgTmp = cvCreateImage(cvSize(640, 480), IPL_DEPTH_8U, 1);
                imgR = cvCreateImage(cvSize(640, 480), IPL_DEPTH_8U, 1); //Red
                imgG = cvCreateImage(cvSize(640, 480), IPL_DEPTH_8U, 1); //Green
                imgB = cvCreateImage(cvSize(640, 480), IPL_DEPTH_8U, 1); //Blue
                while (1) {
                    // データの更新を待つ
                    capture.grab();
                    // RGBを取得して表示
                    capture.retrieve(RGBMap, CV_CAP_OPENNI_BGR_IMAGE);
                    ipl_RGB = RGBMap;
                    RGB_image = &amp;ipl_RGB;
                    cvSplit(RGB_image, imgB, imgG, imgR, NULL);
                    // 赤の要素が100以上で、緑と青より1.5倍以上あるピクセルを抽出
                    cvThreshold(imgB, imgThreshold_B, 100, 255, CV_THRESH_BINARY);
                    cvDiv(imgB, imgG, imgTmp, 10); // 10倍
                    cvThreshold(imgTmp, imgThreshold_G, 18, 255, CV_THRESH_BINARY);
                    cvDiv(imgB, imgR, imgTmp, 10);
                    cvThreshold(imgTmp, imgThreshold_R, 18, 255, CV_THRESH_BINARY);
                    cvAnd(imgThreshold_G, imgThreshold_R, imgTmp, NULL);
                    cvAnd(imgTmp, imgThreshold_B, imgResult, NULL);
                    cvAnd(imgThreshold_G, imgThreshold_R, imgTmp, NULL);
                    cvAnd(imgTmp, imgThreshold_B, imgResult, NULL);

                    //ラベリング
                    labeling.Exec((uchar *)imgResult-&gt;imageData, dst, imgResult-&gt;width, imgResult-&gt;height, true, 30);
                    if (labeling.GetNumOfResultRegions() != 0) {
                        ri = labeling.GetResultRegionInfo(0);
                        //四角形の描画
                        int ltop_x, ltop_y, rbottom_x, rbottom_y;
                        ri-&gt;GetMin(ltop_x, ltop_y);
                        ri-&gt;GetMax(rbottom_x, rbottom_y);
                        cvLine(RGB_image, cvPoint(ltop_x, ltop_y), cvPoint(rbottom_x, ltop_y), CV_RGB(255, 255, 255));
                        cvLine(RGB_image, cvPoint(rbottom_x, ltop_y), cvPoint(rbottom_x, rbottom_y), CV_RGB(255, 255, 255));
                        cvLine(RGB_image, cvPoint(rbottom_x, rbottom_y), cvPoint(ltop_x, rbottom_y), CV_RGB(255, 255, 255));
                        cvLine(RGB_image, cvPoint(ltop_x, rbottom_y), cvPoint(ltop_x, ltop_y), CV_RGB(255, 255, 255));
                        float f_x, f_y;
                        ri-&gt;GetCenter(f_x, f_y);
                        x = (int)f_x;
                        y = (int)f_y;
                        capture.retrieve(Cloud, CV_CAP_OPENNI_POINT_CLOUD_MAP);
                        capture.retrieve(valid, CV_CAP_OPENNI_VALID_DEPTH_MASK);
                        if (valid.at&lt;unsigned char&gt;(y, x) == 0xff) {
                            Vec3f s = Cloud.at&lt;Vec3f&gt;(y, x);
                            printf("%f %f %f\n", s[0], s[1], s[2]);  //座標を表示
                        }
                        else {
                            printf("invalid!\n");
                        }
                    }

                    cvShowImage("Window", RGB_image);
                    if (waitKey(10) &gt;= 0) {
                        break;
                    }
                }
                destroyAllWindows();
            }
            catch (...) {
                cout &lt;&lt; "exception!!" &lt;&lt; endl;
            }
        }
    }

    catch (std::exception&amp; ex) {
        std::cout &lt;&lt; ex.what() &lt;&lt; std::endl;
    }
}
</code></pre>
