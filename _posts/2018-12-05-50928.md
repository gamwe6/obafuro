---
layout: post
title: "スクレイプ結果の出力"
date: 2018-12-05 08:11:51
categories: python pandas web-scraping google-colaboratory
---
<p><a href="https://ja.stackoverflow.com/questions/50914/phantomjs%E3%81%A7%E5%8F%8E%E9%9B%86%E3%81%97%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AEcsv%E3%81%B8%E3%81%AE%E6%A0%BC%E7%B4%8D">以前に回答していただいた点</a>を修正して以下の様なコードを実行したのですが、欲しい出力が何も表示されずにプログラムが終了してしまいます...。何か原因に心あたりのある方がいらっしゃれば回答いただけると助かります。</p>

<pre><code>#https://review-of-my-life.blogspot.com/2017/10/python-web-scraping-data-collection-analysis.htmlの練習
#trendAnalytics.py
from selenium import webdriver  
from pandas import * 
import time

#Access to page
# PATH を指定した上で WebDriver を用意
browser = webdriver.PhantomJS(executable_path="/content/phantomjs-2.1.1-linux-x86_64/bin/phantomjs") #PhantomJSのサポートは終わっているらしい...?Headless Chromeを使うべきなのか...?
#https://qiita.com/orangain/items/db4594113c04e8801aadを下のセルで試す。
# DO NOT FORGET to set path
url = "http://b.hatena.ne.jp/search/text?safe=on&amp;q=Python&amp;users=50"
browser.get(url)
#!touch trend.csv
#df = pandas.read_csv('trend.csv') #エラーの要因
df = pandas.DataFrame()　#前回の回答の反映
#Insert title,date,bookmarks into CSV file

page = 1 #This number shows the number of current page later

while True: #continue until getting the last page
  if len(browser.find_elements_by_css_selector(".pager-next")) &gt; 0:
    print("######################page: {} ########################".format(page))
    print("Starting to get posts...")
    posts = browser.find_elements_by_css_selector(".search-result")#何かを取得している...。

    for post in posts:
      title = post.find_element_by_css_selector("h3").text
      date = post.find_element_by_css_selector(".created").text
      bookmarks = post.find_element_by_css_selector(".users span").text
      se = pandas.Series([title, date, bookmarks],['title','date','bookmarks'])
      df = df.append(se, ignore_index=True)
      print(df)

    #after getting all posts in a page, click pager next and then get next all posts again
    btn = browser.find_element_by_css_selector("a.pager-next").get_attribute("href")#次に投稿を取得するページのurlっぽい。
    print("next url:{}".format(btn))
    browser.get(btn)#次のページへ移動
    page+=1
    browser.implicitly_wait(10)#sleep()みたいなものか...?
    print("Moving to next page......")
    time.sleep(10)#これ要る...?

  else: #if no (next) pager exist, stop.
    print("no pager exist anymore")
    break
#while文終わり

df.to_csv("trend1.csv")
print("DONE")
</code></pre>

<p>出力</p>

<pre><code>/usr/local/lib/python3.6/dist-packages/selenium/webdriver/phantomjs/webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '
no pager exist anymore
DONE
</code></pre>
