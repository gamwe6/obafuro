---
layout: post
title: Spark DataFrameに ネストしたJsonファイルからデータを読み込みたい
date: 2017-09-08 08:09:38
categories: json python3 spark
---
<p>pysparkを使用しています。Spark 2.1以降であれば、スキーマ定義を行った後にJsonファイルを読み込むことができます。</p>

<hr>

<p>例1<br>
 test01.json</p>

<pre><code>{
 "_id":"2d3erf5",
 "testNo":"0001",
 "Date":"2017-09-01 00:00:00.00000"
}
</code></pre>

<p>test01.py</p>

<pre><code>from pyspark.sql import SparkSession
from pyspark.sql.types import *

spark = SparkSession.builder.appName('Spark SQL and DataFrame').getOrCreate()


testColumn = StructType([
  StructField('_id', StringType(), False),
  StructField('testNo', IntegerType(), False),
  StructField('Date', TimestampType(), False)
])
readFile = '/tmp/test01.json'
test_df = spark.read.json(readFile, schema=testColumn)
</code></pre>

<hr>

<p>今回、ネストされているJsonファイルを読み込む必要があるのですが、どう記述すればよろしいのでしょうか？</p>

<hr>

<p>例2<br>
 test02.json</p>

<pre><code>{
  "_id":"2d3erf5",
  "testNo":"0001",
  "test_date"{
              "date_1":"2017-09-01 00:00:00.00000",
              "date_2":"2017-09-05 03:00:00.00000"
             }
}
</code></pre>

<p>以下のような感じに記述するのかなとは、思っていますが、どなたかご教授願います。</p>

<p>test02.py</p>

<pre><code>from pyspark.sql import SparkSession
from pyspark.sql.types import *

spark = SparkSession.builder.appName('Spark SQL and DataFrame').getOrCreate() 


testColumn = StructType([
  StructField('_id', StringType(), False),
  StructField('testNo', IntegerType(), False),
  StructField('test_date.date_1', TimestampType(), False),
  StructField('test_date.date_2', TimestampType(), False),
])
readFile = '/tmp/test02.json'
test_df = spark.read.json(readFile, schema=testColumn)
</code></pre>
