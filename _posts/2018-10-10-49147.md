---
layout: post
title: ランダムフォレスト 、一つ抜き交差検証におけるfeature importanceの出力
date: 2018-10-10 14:15:59
categories: python python3 scikit-learn
---
<p>ランダムフォレスト、一つ抜き交差検証を用いて、予測モデルの作成を行っています。<br>
ランダムフォレストでは、feature importanceを出力できますが、一つ抜き交差検証を用いた時の、平均のfeature importanceを出力することは可能なのでしょうか？<br>
可能な場合、どのようなコードを足せばよろしいでしょうか？<br>
現在のコードは以下の通りです。</p>

<pre><code>import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import LeaveOneOut
data = np.loadtxt('****.csv', delimiter=',',skiprows=1,dtype=float)
labels = data[:, 0:1]
features = data[:, 1:]
forest=RandomForestClassifier(n_estimators=100,random_state=7)
loo=LeaveOneOut()
scores = cross_val_score(forest, features, labels.ravel(), cv=loo)

feature_name= np.loadtxt('feature_name.csv', delimiter=',', dtype=str)
import matplotlib.pyplot as plt
def plot_feature_importances(model):
    n_features = features.shape[1] 
    plt.barh(range(n_features), model.feature_importances_, align='center') 
    plt.yticks(np.arange(n_features), feature_name) 
    plt.xlabel('importances') 
    plt.ylabel('features') 
    plt.show()
</code></pre>
