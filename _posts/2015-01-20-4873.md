---
layout: post
title: iOS (Swift) で、動画撮影中のデバイス回転時の処理について
date: 2015-01-20 01:38:34
categories: ios swift
---
<!-- {% raw %} -->
<p>はじめまして。</p>

<p>現在、 Swift で動画撮影アプリを制作しておりますが、デバイスを縦横に回転させた際の処理で困っています。</p>

<p>デバイスを傾けたときに、撮影枠は縦横対応にうまく対応できたのですが、それに伴って被写体がうまく回転してくれません。いろいろ調べていますが、アプリ開発の初心者ということもあり、いまいち修正ポイントがわかっていません。</p>

<p>画面回転時のメソッドの中で、 <code>CameraEngine.swift</code> の <code>startup</code> 処理の何かを再度、設定するべきなのかなど、初心者なりに悩んでおります。</p>

<p>どなたか、アドバイスをいただけないでしょうか？何卒よろしくお願いいたします。</p>

<p>以下に、修正すべきところと思われるソースの一部を抜粋させていただきます。</p>

<p>【ViewController.swift】</p>

<pre><code>override func viewDidLoad(){
    super.viewDidLoad()

    // カメラエンジンスタート
    self.cameraEngine.startup()

    videoLayer = AVCaptureVideoPreviewLayer.layerWithSession(self.cameraEngine.captureSession) as AVCaptureVideoPreviewLayer

    // 画面セットアップ
    setupScreen()
}

// 画面回転時に呼び出される
override func willAnimateRotationToInterfaceOrientation(toInterfaceOrientation: UIInterfaceOrientation, duration: NSTimeInterval) {

    // 画面セットアップ
    setupScreen()
}

// 画面セットアップ
func setupScreen(){
    // ビデオレイヤー設定
    videoLayer.frame = self.view.bounds
    videoLayer.videoGravity = AVLayerVideoGravityResizeAspectFill
    self.view.layer.addSublayer(videoLayer)
}
</code></pre>

<p>【CameraEngine.swift】</p>

<pre><code>func startup(){

    // video input
    self.videoDevice.activeVideoMinFrameDuration = CMTimeMake(1, 30)

    var captureDevice: AVCaptureDevice?
    // バックカメラ
    captureDevice = self.videoDevice

    let videoInput = AVCaptureDeviceInput.deviceInputWithDevice(captureDevice, error: nil) as AVCaptureDeviceInput

    self.captureSession.addInput(videoInput)

    // audio input
    let audioInput = AVCaptureDeviceInput.deviceInputWithDevice(self.audioDevice, error: nil)  as AVCaptureDeviceInput
    self.captureSession.addInput(audioInput);

    // video output
    var videoDataOutput = AVCaptureVideoDataOutput()
    videoDataOutput.setSampleBufferDelegate(self, queue: self.recordingQueue)
    videoDataOutput.alwaysDiscardsLateVideoFrames = true
    videoDataOutput.videoSettings = [
        kCVPixelBufferPixelFormatTypeKey : kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange
    ]
    self.captureSession.addOutput(videoDataOutput)

    self.height = videoDataOutput.videoSettings["Height"] as Int!
    self.width = videoDataOutput.videoSettings["Width"] as Int!

    // audio output
    var audioDataOutput = AVCaptureAudioDataOutput()
    audioDataOutput.setSampleBufferDelegate(self, queue: self.recordingQueue)
    self.captureSession.addOutput(audioDataOutput)

    self.captureSession.startRunning()
}
</code></pre>

<p>【追記】20150121<br>
<img src="https://i.stack.imgur.com/m1WyV.png" alt="デバイス横のイメージ"><br>
デバイス横のイメージ</p>

<p><img src="https://i.stack.imgur.com/Vhs7z.png" alt="デバイス縦のイメージ"><br>
デバイス縦のイメージ</p>
<!-- {% endraw %} -->
