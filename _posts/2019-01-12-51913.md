---
layout: post
title: python seleniumを使っていると処理が止まる？
date: 2019-01-12 08:41:58
categories: python selenium
---
<!-- {% raw %} -->
<p>初めまして．<br>
pythonでスクレイピングをしています．<br>
しかし，大量に(数十~数百件)下記のようなプログラムでhtmlを得ていると，<br>
<code>browser.page_source</code>で処理が止まってしまいます．<br>
エラーが出るわけでもなく，数十分しても動き出しません．</p>

<p>同じような状況の方はいらっしゃいますでしょうか．<br>
また，解決した方がいらっしゃいましたら，その方法を教えてください．</p>

<p>よろしくお願いいたします．</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.chrome.options import Options
# ブラウザーを起動
options = Options()
options.add_argument('--headless')
# Chromeのドライバを得る
browser = webdriver.Chrome(chrome_options=options)

browser.set_script_timeout = 30
browser.timeout = 30
browser.implicitly_wait = 30
browser.set_page_load_timeout = 30
browser.get(url)
# htmlを取得
html = browser.page_source
</code></pre>

<p><strong>追記1</strong>:<br>
コメントありがとうございます．<br>
大量に取得する部分ですが，<br>
urlのリスト<code>urls = ["https://~~", "https://~~", ...]</code>といったものを作成し，</p>

<pre><code>for url in urls:
  scraping(url)
</code></pre>

<p>という風に記載しています．<br>
scraping(url)は上記のようなプログラムです．</p>

<p><strong>追記2</strong>:<br>
コメントありがとうございます．</p>

<blockquote>
  <p>scraping(url)は上記のようなプログラムです．</p>
</blockquote>

<p>この書き方がよくありませんでした．<br>
すみません．<br>
最初に提示したプログラムがscraping(url)です．<br>
ですので，</p>

<pre><code>def scraping(url):
  # ブラウザーを起動
  options = Options()
  options.add_argument('--headless')
  # Chromeのドライバを得る
  browser = webdriver.Chrome(chrome_options=options)

  browser.set_script_timeout = 30
  browser.timeout = 30
  browser.implicitly_wait = 30
  browser.set_page_load_timeout = 30
  browser.get(url)
  # htmlを取得
  html = browser.page_source
  return (html)
</code></pre>

<p>このようなプログラムです．</p>

<p>運がいいときは，止まらずに数百件の処理を行いますが，<br>
悪いと，数件処理した後にhtml = の部分で止まります．</p>
<!-- {% endraw %} -->
