---
layout: post
title: "Pythonでプログラムを実行している階層より上のモジュールをimportしたい。"
date: 2017-11-21 12:37:09
categories: python python3 flask
---
<p>　Pythonで検索エンジンを作成したのですがクライアントから任意のURLをpostで送ってクローラーを起動させたいのです。<br>
フレームワークはflaskを使用しています。</p>

<pre><code>■検索エンジン
|---■config.py
|---■manage.py
|---■web_crawler
　　|---■\__init__.py
　　|---■crawler.py
　　|---■drop_collection.py
|---■search_engine
　　|---■\__init__.py
　　|---■template
　　　　|---■index.html
</code></pre>

<p>　現在はmanage.pyからcrawlerとsearch_engineを動作させています。<br>
crawlerで最初にwebサイトをクローリングしておいて、その後に検索エンジンを動作させる方法で動いています。</p>

<p>manage.py</p>

<pre><code># -*- coding: utf-8 -*-
import argparse
__author__ = 'wataru'


if __name__ == '__main__':
    #エラーの時にメッセージを表示する。 
    parser = argparse.ArgumentParser("Runner")
    parser.add_argument('action', type=str, nargs=None, help="Select target 'crawler' or 'webpage'?")
    args = parser.parse_args()

    if args.action == 'crawler':
        #コマンドラインでcrawlerって打ち込まれたらweb_crawlerって言うフォルダからcrawler.pyを読み込んでcrawl_webっていうdefを持ってくる    
        from web_crawler.crawler import crawl_web
        crawl_web('http://ltomu.minibird.jp/', 2)
    elif args.action == 'webpage':
        from search_engine import app
        app.run(debug=True, host='0.0.0.0', port=9000)
    elif args.action == 'dropdb':
        from web_crawler.drop_collection import drop_collection
        drop_collection()
    else:
        raise ValueError('Please select "crawler" or "webpage" or "dropdb".')
</code></pre>

<p>　現在の構成だとsearch_engineの中にある__init__.pyに検索エンジンのプログラムwebサイトを表示するプログラムが書いてあるのですがこの__init__.pyにcrawler.pyをimportしたいのですがPythonのimportは実行ディレクトリと同様のディレクトリかカレントディレクトリでしかimport出来ないので上の階層はsysを使うと知ったのですがどのように記述したら良いのかわかりません。</p>

<p>以下のコードにsysを追加してcrawler.pyをimportしたい。<br>
＿init＿.py</p>

<pre><code>from urllib.parse import urlparse
from flask import Flask, render_template, request
from pymongo import MongoClient

app = Flask(__name__)
app.config.from_object('config') #flaskのconfigを読み込んでる

# DB settings
MONGO_URL = app.config['MONGO_URL']
client = MongoClient(MONGO_URL)
db = client[urlparse(MONGO_URL).path[1:]]
col = db["Index"]


@app.route('/', methods=['GET', 'POST']) #postはフォームにキーワード
def index():
    """Return index.html
    """
    if request.method == 'POST':
        keyword = request.form['keyword'] #フォームで入力された文字がkeyword変数に入っているのでそれを持ってくるそこからkeywordに代入
        if keyword:
            if keyword == 'wataru':
                redirect(url_for('crawler'))
            return render_template(
                'result.html',
                query=col.find_one({'keyword': keyword}),
                keyword=keyword)
    return render_template('index.html')

@app.route('/crawler', methods=['GET', 'POST'])
def crawlerpage():
    """Return index.html
    """
    if request.method == 'POST':
        url = request.form['url'] 
        if 'http' in url:
                crawl_web(url, 1) #ここをcrawlerを使うためimportしたい
                return render_template('done.html')
    return render_template('crawler.html')
</code></pre>

<p>詳しい方お力を貸して頂けると幸いです。</p>
