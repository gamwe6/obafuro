---
layout: post
title: BaggingClassifierのパラメーターについて
date: 2017-11-22 19:09:39
categories: python scikit-learn
---
<pre><code>  clf = DecisionTreeClassifier(criterion='entropy', max_depth=1)          
  sklearn.ensemble.BaggingClassifier(base_estimator=clf, n_estimators=10, max_samples=1, max_features=1)
</code></pre>

<p>上記のパラメータbase_estimator=clf1, n_estimators=10, max_samples=1, max_features=1はそれぞれ何を表しているのでしょうか。<br>
n_estimatorsは決定木の個数、 max_samplesはそれぞれの決定木に使われる(抽出サンプル数/全体数)という割合、max_featuresはそれぞれの決定木に使われる（抽出サンプルの特徴量数/全体の特徴量数）という割合であっていますでしょうか。</p>

<p>また、上記理解が正しい場合、さらに以下の疑問があります。<br>
max_samples=1のとき全体が抽出されるので、自動的に特徴量もmax_features=1になるような気がしており、どちらか一つの特徴量で良いのではないかと思っています。</p>
