---
layout: post
title: AVFoundationを使用したカメラの実装についての疑問点
date: 2015-11-20 09:48:45
categories: ios swift avfoundation
---
<p>４日ほど前にこちらで（<a href="https://teratail.com/questions/20295" rel="nofollow">https://teratail.com/questions/20295</a>）質問をさせていただき回答もしていただけたのですが、まだわからない点があるのでもう少し情報をいただければと考え、同じ内容の質問をさせていただきます。</p>

<p>現在、AVFoundationを使ってカメラ機能を作りたいと考えています。 </p>

<p>カメラの機能は、フラッシュやフォーカスなど基本的な機能に加えて、evernoteのIOSアプリのように撮った写真のサムネイルが撮影中の画面に並んでいき、撮影した複数の写真データを次の画面に渡せるようなものです。インスタグラムのような加工機能は考えていません。 </p>

<p>そこで、AVFoundationの使い方を調べたところ、AVCaptureVideoDataOutputとAVCaptureStillImageOutputを使用する二種類のやり方があることがわかりました。 </p>

<p>しかし、それぞれの利点や違いがいまいちよくわかりませんでした。 </p>

<p>質問としては、 <br>
１二種類の方法のそれぞれの違いや利点、こういう時はこちらを使うよといったことを教えてください。 <br>
２また、上記のようなカメラの実装ならこっちを使った方が良いといったことも教えていただきたいです。 </p>

<p>よろしくお願いします！</p>
