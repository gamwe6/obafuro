---
layout: post
title: "株価の予測にこのニューラルネットワークは間違っていませんか？"
date: 2019-10-06 07:09:42
categories: 機械学習 deeplearning4j rnn
---
<p>株価の予測をしたいのですが、なかなかうまく行きません。<br>
具体的には学習が全く進まないです。<br>
私のこのニューラルネットワークの使い方自体は間違っていませんか？</p>

<p>[Input]（すべて平均に対する倍率で正規化されています）<br>
0 株価　始値<br>
1 株価　高値<br>
2 株価　安値<br>
3 株価　終値<br>
4 この日の特徴A<br>
5 この日の特徴B</p>

<p>この日の特徴AとBは独自アルゴリズムで計算したその日の特徴になります。<br>
今後の株価の上昇などに関連性があります。</p>

<p>私は誤検知を取り除きたいために機械学習をしようと試みています。</p>

<p>[Output]いずれかが1になります<br>
0 最後のタイムステップから10日以内に1割上昇<br>
1 最後のタイムステップか10日以内に特に変動なし<br>
2 最後のタイムステップか10日以内に1割下洛</p>

<p>タイムステップは100です。<br>
ミニバッチは32です。<br>
epochは10です。（最初は1だったけど学習が微動だにしないので上げた）</p>

<p><a href="https://i.stack.imgur.com/CFzj1.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/CFzj1.png" alt="画像の説明をここに入力"></a></p>

<pre><code>===========INPUT===================
[[[    1.0357,    1.0513,    1.0147  ...    0.9730    0.9695,    0.9734], 
  [    1.0388,    1.0341,    1.0022  ...    0.9656    0.9734,    0.9734], 
  [    1.0427,    1.0513,    1.0201  ...    0.9734    0.9734,    0.9738], 
  [    1.0318,    1.0287,    0.9855  ...    0.9656    0.9664,    0.9734], 
  [    1.6755,    1.2601,    0.3456  ...         0    0.7736,    6.7037], 
  [    0.3751,    0.3616,    1.1761  ...    0.2864    0.5629,    0.4131]], 

 [[    1.0821,    1.0801,    1.0601  ...    1.3061    1.3001,    1.2961], 
  [    1.1001,    1.0901,    1.0401  ...    1.2981    1.2821,    1.3381], 
  [    1.1001,    1.0901,    1.0601  ...    1.3101    1.3001,    1.3381], 
  [    1.0801,    1.0621,    1.0241  ...    1.2601    1.2821,    1.2961], 
  [    0.0688,    0.9349,    0.0838  ...    1.6641         0,    0.3009], 
  [    1.3479,    0.0673,         0  ...    0.6315    0.9210,   58.8286]], 

 [[    1.0900,    1.0708,    1.0708  ...    1.0900    1.0836,    1.0772], 
  [    1.0772,    1.0580,    1.1157  ...    1.0836    1.0708,    1.0516], 
  [    1.0964,    1.0708,    1.1157  ...    1.0900    1.0836,    1.0772], 
  [    1.0772,    1.0451,    1.0708  ...    1.0772    1.0708,    1.0516], 
  [    0.2267,    0.9888,         0  ...    0.5150    2.3653,         0], 
  [    1.7519,    0.6446,    1.7559  ...    2.0206    0.2649,    9.3929]], 

  ..., 

 [[    0.9925,    0.9925,    0.9953  ...    1.0109    1.0091,    1.0119], 
  [    0.9925,    0.9971,    0.9888  ...    1.0063    1.0119,    1.0082], 
  [    0.9971,    0.9980,    0.9953  ...    1.0119    1.0119,    1.0128], 
  [    0.9925,    0.9879,    0.9852  ...    1.0063    1.0073,    1.0063], 
  [    0.5251,    0.5053,    0.4411  ...    1.9785    0.9391,    7.1644], 
  [    0.9026,         0,    0.8412  ...    0.1732    0.1513,    0.0467]], 

 [[    0.7903,    0.7764,    0.7875  ...    1.0193    1.0165,    0.9216], 
  [    0.7764,    0.8015,    0.7819  ...    1.0221    1.0109,    0.9160], 
  [    0.7959,    0.8015,    0.7959  ...    1.0584    1.0556,    0.9355], 
  [    0.7764,    0.7764,    0.7819  ...    1.0193    1.0054,    0.8881], 
  [    0.7363,    0.3788,    0.3158  ...    0.4995    0.6567,    6.4159], 
  [    0.1783,    0.3246,    0.8313  ...    0.6535    0.3348,    0.1456]], 

 [[    0.8960,    0.9086,    0.9194  ...    0.9844    0.9553,    0.9875], 
  [    0.8935,    0.9169,    0.9068  ...    0.9680    0.9585,    1.0159], 
  [    0.8960,    0.9219,    0.9225  ...    0.9869    0.9831,    1.0229], 
  [    0.8821,    0.9023,    0.9017  ...    0.9642    0.9553,    0.9818], 
  [    4.5974,         0,    0.6352  ...    0.4522    0.6429,    0.7656], 
  [    0.3374,    0.3450,    1.0265  ...    1.5891    2.2172,    7.6396]]]
=================OUTPUT==================
[[[         0,         0,         0  ...         0         0,         0], 
  [         0,         0,         0  ...         0         0,    1.0000], 
  [         0,         0,         0  ...         0         0,         0]], 

 [[         0,         0,         0  ...         0         0,    1.0000], 
  [         0,         0,         0  ...         0         0,         0], 
  [         0,         0,         0  ...         0         0,         0]], 

 [[         0,         0,         0  ...         0         0,         0], 
  [         0,         0,         0  ...         0         0,         0], 
  [         0,         0,         0  ...         0         0,    1.0000]], 

  ..., 

 [[         0,         0,         0  ...         0         0,         0], 
  [         0,         0,         0  ...         0         0,         0], 
  [         0,         0,         0  ...         0         0,    1.0000]], 

 [[         0,         0,         0  ...         0         0,         0], 
  [         0,         0,         0  ...         0         0,    1.0000], 
  [         0,         0,         0  ...         0         0,         0]], 

 [[         0,         0,         0  ...         0         0,    1.0000], 
  [         0,         0,         0  ...         0         0,         0], 
  [         0,         0,         0  ...         0         0,         0]]]
===========INPUT MASK===================
[[    1.0000,    1.0000,    1.0000  ...    1.0000    1.0000,    1.0000], 
 [    1.0000,    1.0000,    1.0000  ...    1.0000    1.0000,    1.0000], 
 [    1.0000,    1.0000,    1.0000  ...    1.0000    1.0000,    1.0000], 
  ..., 
 [    1.0000,    1.0000,    1.0000  ...    1.0000    1.0000,    1.0000], 
 [    1.0000,    1.0000,    1.0000  ...    1.0000    1.0000,    1.0000], 
 [    1.0000,    1.0000,    1.0000  ...    1.0000    1.0000,    1.0000]]
===========OUTPUT MASK===================
[[         0,         0,         0  ...         0         0,    1.0000], 
 [         0,         0,         0  ...         0         0,    1.0000], 
 [         0,         0,         0  ...         0         0,    1.0000], 
  ..., 
 [         0,         0,         0  ...         0         0,    1.0000], 
 [         0,         0,         0  ...         0         0,    1.0000], 
 [         0,         0,         0  ...         0         0,    1.0000]]
</code></pre>

<pre><code>NumInputs = 6
NumOutputs = 3
NumLstmLayers = 256
val conf = NeuralNetConfiguration.Builder()
                .seed(19920528)
                .weightInit(WeightInit.XAVIER)
                .miniBatch(true)
                .updater(Adam())
                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)

                .list()
                .layer(LSTM.Builder()
                        .nIn(NumInputs)
                        .nOut(NumLstmLayers)
                        .activation(Activation.TANH)
                        .build()
                )
                .layer(LSTM.Builder()
                        .nIn(NumLstmLayers)
                        .nOut(NumLstmLayers)
                        .activation(Activation.TANH)
                        .build()
                )
                .layer(RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT)
                        .nIn(NumLstmLayers)
                        .nOut(NumOutputs)
                        .activation(Activation.SOFTMAX)
                        .build()
                )

//               .backpropType(BackpropType.TruncatedBPTT)
//                .tBPTTForwardLength(5)
//                .tBPTTBackwardLength(5)
                .build()

        val nn = MultiLayerNetwork(conf)
        nn.init()
</code></pre>

<p>追記<br>
もしかしたら解決…？<br>
ミニバッチで学習していますが、そのミニバッチ内のアウトプットパターンが均等になるようにデータを用意していました。<br>
今回の場合、アウトプットが3パターンならミニバッチの数を3の倍数にし、</p>

<pre><code>out[0]=0
out[1]=0
out[2]=1

out[0]=0
out[1]=1
out[2]=0

out[0]=1
out[1]=0
out[2]=0

out[0]=0
out[1]=0
out[2]=1

out[0]=0
out[1]=1
out[2]=0

out[0]=1
out[1]=0
out[2]=0
</code></pre>

<p>のようにアウトプットパーターンが均等になるようにデータを用意していました。<br>
ミニバッチなのでアウトプットが相殺されて学習できなかったのでしょうか？</p>
