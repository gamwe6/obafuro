---
layout: post
title: Python スクレイピング　同じ項目は同じ列に記載、異なる項目は新しく列を追加して記載する方法
date: 2019-10-12 10:56:00
categories: python csv web-scraping beautifulsoup
---
<p>当方初心者であり、申し訳ないのですが皆様のお知恵を拝借したいです。</p>

<p>いろいろ検索したのですが、良い方法（どこから手をつけるべきか）がわからず、<br>
困っております。アドバイスいただけますと幸いです。</p>

<p>ページをスクレイピングして、CSVに下記のようなデータを書き出すプログラムを作りました。</p>

<pre><code>a,b,d,x,テスト 
3354,test,あいうえ,いろはに,12345
</code></pre>

<p>この時、複数のページをスクレイピングして同様の情報を取得するプログラムを実行し、<br>
行を追加して値を記載していくプログラムを作りたいと考えています。</p>

<p>ただ、ページ毎にカラム名が同じ場合もあれば、異なる場合もあります。</p>

<p>もし、スクレイピングした2ページ目がこのような値の場合は、</p>

<pre><code>a,b,d,y,テスト 
3399,TEST,あいうえ,ほへと,12345
</code></pre>

<p>CSVに書き出す場合は下記のように記載したいと考えています。</p>

<pre><code>a,b,d,x,テスト,y 
3354,test,あいうえ,いろはに,12345
3399,TEST,あいうえ,,12345,ほへと
</code></pre>

<p>※基本的には順に行追加で値が記載されていき、<br>
　新しい項目の場合は一番右側に列が追加されそこに記載されていく、、という流れです。</p>

<p>複数ページに順にアクセスして、それぞれのページの情報を取得するコードはできたのですが、各項目に希望通りにCSVに書き出す部分が不明です。</p>

<p>この場合、どのようなプログラムが適切でしょうか？<br>
何か参考になる具体的なコード、サイトなどありましたら、<br>
教えて頂けませんでしょうか。。。。。</p>

<p>【追記】<br>
質問を頂きありがとうございます。<br>
カラムにある記載を事前に予想できないことがネックとなります。</p>

<p>取得する情報は1ページ毎に商品のスペック情報のようなものです。<br>
Aという商品にはa,b,c,dというスペックの項目があり（上記で言うカラムにある記載）、<br>
それぞれに対して、あ,い,う,えという値が取得できます。</p>

<p>Bという商品を取得すると、Aという商品と同じスペック項目はあるケースもありますが（ただし値は異なる）、Bにしかないスペック項目もあります。</p>

<p>毎度取得する情報はスペック項目と値のセットとなりますので、</p>

<pre><code>a,b,d,x,テスト,y 
3354,test,あいうえ,いろはに,12345
3399,TEST,あいうえ,,12345,ほへと
</code></pre>

<p>取得する毎に上記のように行が追加され、且つ以前取得したスペック項目が無い場合は、<br>
新しく追加されていくことが理想です。</p>

<p>【追記2】<br>
現在のコードは下記のようにしておりまして、<br>
ページを読み込む→データを取得→CSVに書き込むというのをfor文で作成しています。</p>

<pre><code>for num in range(1,xxx):
    urlclick = driver.find_element_by_xpath('xxxxxxxxxxx'.format(num))
    urlclick.click()
    driver.window_handles
    driver.switch_to.window(driver.window_handles[1])
    currentURL = driver.current_url
    html = urlopen(currentURL)
    bsObj = BeautifulSoup(html, "html.parser")
    table = bsObj.findAll("table", {"class":"xxxxxxxxxxx'"})[0]
    rows = table.findAll("tr")
    data = []
    for row in rows:
        csvRow = []
        for cell in row.findAll(['td', 'th']):
            csvRow.append(cell.get_text(strip=True))
        data.append(csvRow)

    col1 = [a[:2] for a in data]
    col2 = [a[2:] for a in data]

    col1.extend(col2)

    row1 = [a[:1] for a in col1]
    row2 = [a[1:] for a in col1]

    row1 = sum(row1, [])
    row2 = sum(row2, [])

    array2d = [row1, row2]
</code></pre>
