---
layout: post
title: "テキスト中の単語をTF-IDFのスコア順に並べ替えたい"
date: 2019-08-15 02:41:15
categories: python 自然言語処理
---
<h3>テキストファイル中の名詞をtf-idfのスコア順に並べたい。</h3>

<p>Pythonで、ツイートを格納したテキストをMeCab(+natto)で形態素解析し、抽出した名詞のtf-idfのスコアを出して並べ替えたいです。コードを走らせた結果、以下のエラーが出ました。<br>
プログラミングを始めたばかりで頼れる人もおらず、何が起きていて、どのように直せばいいのか本当に分からず、質問させていただきました。<br>
お知恵をお貸しいただけませんでしょうか？</p>

<pre><code>Traceback (most recent call last):
  File "tfidf_test_dataset.py", line 41, in &lt;module&gt;
    tfidf = vectorizer.fit_transform(corpus)
  File "/Users/macuser/Workspaces/jxpress/trendword/.direnv/python-3.7.3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py", line 1652, in fit_transform
    X = super().fit_transform(raw_documents)
  File "/Users/macuser/Workspaces/jxpress/trendword/.direnv/python-3.7.3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py", line 1058, in fit_transform
    self.fixed_vocabulary_)
  File "/Users/macuser/Workspaces/jxpress/trendword/.direnv/python-3.7.3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py", line 970, in _count_vocab
    for feature in analyze(doc):
  File "/Users/macuser/Workspaces/jxpress/trendword/.direnv/python-3.7.3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py", line 352, in &lt;lambda&gt;
    tokenize(preprocess(self.decode(doc))), stop_words)
  File "/Users/macuser/Workspaces/jxpress/trendword/.direnv/python-3.7.3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py", line 256, in &lt;lambda&gt;
    return lambda x: strip_accents(x.lower())
AttributeError: 'generator' object has no attribute 'lower'
</code></pre>

<h3>該当のソースコード</h3>

<pre class="lang-py prettyprint-override"><code>from natto import MeCab
import codecs
import sys
import re
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

with codecs.open("tfidf_test.txt", "r", "utf-8") as f:
    corpus = f.read().split("\n")

mecab = MeCab('-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')

#if tagger.lang == 'ja':
for txt in corpus:
    words = mecab.parse(txt, as_nodes=True)

    for w in words:
        rm_list = ["RT","https","co"]
        if w.feature.split(",")[0] == "名詞":
            if len(w.surface) &gt;= 2:
                if not any(rm in w.surface for rm in rm_list):
                    print(str(w.surface))
                else:
                    print("")
            else:
                print("")
        else:
            print("")

corpus = [mecab.parse(txt, as_nodes=True) for line in corpus]

vectorizer = TfidfVectorizer()
tfidf = vectorizer.fit_transform(corpus)

#スコアの表示
print(tfidf.toarray())
# テキストの数、出現した単語の数
print(tfidf.shape)

#並べ替え
feature_names = np.array(vectorizer.get_feature_names())
for vec in tfidf:
    index = np.argsort(vec.toarray(), axis=1)[:,::-1]
    feature_words = feature_names[index]
    print(feature_words[:,:10])
</code></pre>

<pre><code>自転車やバイクで世界を回っている男性が必死で追いかけてくる子猫と出会い、彼の旅を変えたおはなし

京都吹奏楽コンクール高校生小編成の部で金賞をとることができました！ここまで支えてくださった方々のおかげです沢山の応援ありがとうござました

今年も平谷村役場裏のひまわり畑で撮影しました。撮影した殆どの写真が変顔の自分。いちばんまともな顔の写真を。どこにいるかわかりにくいですが
</code></pre>

<h3>補足情報（FW/ツールのバージョンなど）</h3>

<p>iOS 10.12.6, Python 3.7.3, Atom</p>
